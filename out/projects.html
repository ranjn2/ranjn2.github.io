<!DOCTYPE html><html lang="en" class="__variable_87c02c"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/111c93f1bc244164-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/828e2958d60bafae-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" imageSrcSet="/_next/image?url=%2Fheadshot_ranjani.jpg&amp;w=256&amp;q=75 1x, /_next/image?url=%2Fheadshot_ranjani.jpg&amp;w=384&amp;q=75 2x" fetchPriority="high"/><link rel="stylesheet" href="/_next/static/css/960c33a593ca7c53.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-713be2e9e7f2873d.js"/><script src="/_next/static/chunks/fd9d1056-1f1f859026f5f0fa.js" async=""></script><script src="/_next/static/chunks/117-855f12b44ba69681.js" async=""></script><script src="/_next/static/chunks/main-app-3dc074beef5a7128.js" async=""></script><script src="/_next/static/chunks/554-9c22fc75236f63a2.js" async=""></script><script src="/_next/static/chunks/app/projects/page-3555d5f73920eb08.js" async=""></script><title>Ranjani Narayanan | PhD Candidate @ Georgia Tech</title><meta name="description" content="Expanding how agents can become teammates, not just tools."/><meta name="next-size-adjust"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_87c02c"><div class="min-h-screen bg-white"><div class="md:hidden fixed top-4 left-4 z-50"><button class="p-2 rounded-md border border-slate-200 bg-white" aria-label="Toggle menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu h-5 w-5"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg></button></div><header class="w-full py-8 md:py-12"><div class="flex flex-col items-center" style="opacity:0;transform:translateY(-20px)"><h1 class="text-4xl md:text-5xl font-bold text-slate-900 mb-2 text-center">Ranjani Narayanan</h1><p class="text-base md:text-lg text-slate-600 mb-6 text-center">Expanding how agents can become teammates, not just tools.</p><div class="w-32 h-32 md:w-40 md:h-40 rounded-full border-2 border-slate-300 bg-slate-100 mb-6 flex items-center justify-center overflow-hidden"><img alt="Ranjani Narayanan" fetchPriority="high" width="160" height="160" decoding="async" data-nimg="1" class="w-full h-full object-cover" style="color:transparent;object-position:center 25%" srcSet="/_next/image?url=%2Fheadshot_ranjani.jpg&amp;w=256&amp;q=75 1x, /_next/image?url=%2Fheadshot_ranjani.jpg&amp;w=384&amp;q=75 2x" src="/_next/image?url=%2Fheadshot_ranjani.jpg&amp;w=384&amp;q=75"/></div><div class="flex justify-center items-center space-x-4 mb-6"><a href="https://github.com/ranjn2" target="_blank" rel="noopener noreferrer" class="text-slate-600 hover:text-slate-900 transition-colors" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-5 w-5 md:h-6 md:w-6"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a><a href="https://scholar.google.com/citations?user=2cgue9wAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer" class="text-slate-600 hover:text-slate-900 transition-colors" aria-label="Google Scholar"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-graduation-cap h-5 w-5 md:h-6 md:w-6"><path d="M21.42 10.922a1 1 0 0 0-.019-1.838L12.83 5.18a2 2 0 0 0-1.66 0L2.6 9.08a1 1 0 0 0 0 1.832l8.57 3.908a2 2 0 0 0 1.66 0z"></path><path d="M22 10v6"></path><path d="M6 12.5V16a6 3 0 0 0 12 0v-3.5"></path></svg></a><a href="https://www.linkedin.com/in/ranjanin2/" target="_blank" rel="noopener noreferrer" class="text-slate-600 hover:text-slate-900 transition-colors" aria-label="LinkedIn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-linkedin h-5 w-5 md:h-6 md:w-6"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect width="4" height="12" x="2" y="9"></rect><circle cx="4" cy="4" r="2"></circle></svg></a><a href="mailto:nranj2@gmail.com" target="_blank" rel="noopener noreferrer" class="text-slate-600 hover:text-slate-900 transition-colors" aria-label="Email"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mail h-5 w-5 md:h-6 md:w-6"><rect width="20" height="16" x="2" y="4" rx="2"></rect><path d="m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7"></path></svg></a></div><nav class="flex justify-center items-center space-x-6 md:space-x-8"><a class="text-base md:text-lg transition-colors relative pb-1 text-slate-500 hover:text-slate-900" href="/">About Me</a><a class="text-base md:text-lg transition-colors relative pb-1 text-slate-500 hover:text-slate-900" href="/research">Research</a><a class="text-base md:text-lg transition-colors relative pb-1 text-slate-900" href="/projects">Projects<span class="absolute bottom-0 left-0 right-0 h-[1px] bg-blue-600"></span></a><a href="/ranjani-cv.pdf" target="_blank" rel="noopener noreferrer" class="text-base md:text-lg transition-colors relative pb-1 text-slate-500 hover:text-slate-900">CV</a></nav></div></header><main class="max-w-4xl mx-auto px-6 md:px-12 pb-16"><section class="mb-16"><h2 class="text-2xl font-bold text-slate-900 mb-6" style="opacity:0;transform:translateY(20px)">Projects</h2><div class="space-y-8"><div class="flex items-start gap-4" style="opacity:0;transform:translateY(20px)"><div class="flex-1"><div class="flex items-start justify-between gap-4 mb-2"><h3 class="text-lg font-bold text-blue-600">Generative Adversarial Reinforcement Learning</h3><a href="https://github.com" target="_blank" rel="noopener noreferrer" class="text-slate-600 hover:text-slate-900 transition-colors flex-shrink-0 mt-1" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-5 w-5"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a></div><div class="mb-2"><span class="text-red-600 font-medium">[<!-- -->Research<!-- -->]</span><span class="text-slate-600 ml-2">Python, PyTorch, Gym</span></div><p class="text-slate-700 leading-relaxed">Implemented a Generative adversarial RL algorithm which is a model free algorithm on the HalfCheetah-v2 gym environment. The core idea consists of extracting expert policy data to yield expected benchmark rewards. Used Trust Region Policy Optimization to overcome the non-monotonicity problem during training.</p></div></div><div class="flex items-start gap-4" style="opacity:0;transform:translateY(20px)"><div class="flex-1"><div class="flex items-start justify-between gap-4 mb-2"><h3 class="text-lg font-bold text-blue-600">GANs and VAE to Model Multimodal Distribution</h3><a href="https://github.com" target="_blank" rel="noopener noreferrer" class="text-slate-600 hover:text-slate-900 transition-colors flex-shrink-0 mt-1" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-5 w-5"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a></div><div class="mb-2"><span class="text-red-600 font-medium">[<!-- -->Research<!-- -->]</span><span class="text-slate-600 ml-2">Python, PyTorch</span></div><p class="text-slate-700 leading-relaxed">Implemented Variational Autoencoders, DC-GANs and unsupervised image to image translation models namely cycle gan for the FashionMNIST and STL-10 datasets. Used Pytorch for implementation. Used FID and IS loss functions for training and objective performance evaluation.</p></div></div><div class="flex items-start gap-4" style="opacity:0;transform:translateY(20px)"><div class="flex-1"><div class="flex items-start justify-between gap-4 mb-2"><h3 class="text-lg font-bold text-blue-600">Learning Object Pose from UAV Motion</h3><a href="https://github.com" target="_blank" rel="noopener noreferrer" class="text-slate-600 hover:text-slate-900 transition-colors flex-shrink-0 mt-1" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-5 w-5"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a></div><div class="mb-2"><span class="text-red-600 font-medium">[<!-- -->Research<!-- -->]</span><span class="text-slate-600 ml-2">Python, Unity3D, PyTorch</span></div><p class="text-slate-700 leading-relaxed">Created a synthetic dataset of 2d images generated from UAV interaction within a unity3d simulation environment. Implemented domain randomization for augmenting the dataset and improving model robustness. Methods consisted of transfer learning and benchmarking across different image neural nets.</p></div></div><div class="flex items-start gap-4" style="opacity:0;transform:translateY(20px)"><div class="flex-1"><div class="flex items-start justify-between gap-4 mb-2"><h3 class="text-lg font-bold text-blue-600">Object Detection using YOLOv2</h3><a href="https://github.com" target="_blank" rel="noopener noreferrer" class="text-slate-600 hover:text-slate-900 transition-colors flex-shrink-0 mt-1" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-5 w-5"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a></div><div class="mb-2"><span class="text-red-600 font-medium">[<!-- -->Research<!-- -->]</span><span class="text-slate-600 ml-2">Python, PyTorch</span></div><p class="text-slate-700 leading-relaxed">Implemented the end to end pipeline for one shot learning using yolov2 on the xx dataset. Used python and pytorch for the project.</p></div></div><div class="flex items-start gap-4" style="opacity:0;transform:translateY(20px)"><div class="flex-1"><div class="flex items-start justify-between gap-4 mb-2"><h3 class="text-lg font-bold text-blue-600">Image Segmentation using Mask RCNNs, Fast RCNNs and SOLO</h3><a href="https://github.com" target="_blank" rel="noopener noreferrer" class="text-slate-600 hover:text-slate-900 transition-colors flex-shrink-0 mt-1" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-5 w-5"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a></div><div class="mb-2"><span class="text-red-600 font-medium">[<!-- -->Research<!-- -->]</span><span class="text-slate-600 ml-2">Python, PyTorch</span></div><p class="text-slate-700 leading-relaxed">Comparative study of different image segmentation algorithms such as mask rcnn, fast rcnn and one shot solo algorithms. Implemented the end to end pipeline. Implemented a multi-loss paradigm and point-NMS post training filtering methods for evaluation and visualization.</p></div></div><div class="flex items-start gap-4" style="opacity:0;transform:translateY(20px)"><div class="flex-1"><div class="flex items-start justify-between gap-4 mb-2"><h3 class="text-lg font-bold text-blue-600">Deep Learning Based Authorship Identification</h3><a href="https://github.com" target="_blank" rel="noopener noreferrer" class="text-slate-600 hover:text-slate-900 transition-colors flex-shrink-0 mt-1" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-5 w-5"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a></div><div class="mb-2"><span class="text-red-600 font-medium">[<!-- -->Research<!-- -->]</span><span class="text-slate-600 ml-2">Python, PyTorch, LSTM, GRU</span></div><p class="text-slate-700 leading-relaxed">Implemented multi-class classification using lstm, bi-lstm and GRU at sentence level and article levels for corporate news datasets (c50 and Reuters&#x27;). Modeling was done on large corpora of texts. Handled semantic and metaphoric words using stylometric classification, resulting in improved performance.</p></div></div></div></section></main></div><script src="/_next/static/chunks/webpack-713be2e9e7f2873d.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/111c93f1bc244164-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/media/828e2958d60bafae-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n3:HL[\"/_next/static/css/960c33a593ca7c53.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"4:I[2846,[],\"\"]\n6:I[4196,[\"554\",\"static/chunks/554-9c22fc75236f63a2.js\",\"895\",\"static/chunks/app/projects/page-3555d5f73920eb08.js\"],\"default\"]\n7:I[2802,[\"554\",\"static/chunks/554-9c22fc75236f63a2.js\",\"895\",\"static/chunks/app/projects/page-3555d5f73920eb08.js\"],\"default\"]\n8:I[4707,[],\"\"]\n9:I[6423,[],\"\"]\nb:I[1060,[],\"\"]\nc:[]\n"])</script><script>self.__next_f.push([1,"0:[\"$\",\"$L4\",null,{\"buildId\":\"1DU12OJwVRsCJM-5apbwk\",\"assetPrefix\":\"\",\"urlParts\":[\"\",\"projects\"],\"initialTree\":[\"\",{\"children\":[\"projects\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"projects\",{\"children\":[\"__PAGE__\",{},[[\"$L5\",[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-white\",\"children\":[[\"$\",\"$L6\",null,{}],[\"$\",\"main\",null,{\"className\":\"max-w-4xl mx-auto px-6 md:px-12 pb-16\",\"children\":[\"$\",\"$L7\",null,{}]}]]}],null],null],null]},[null,[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L9\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/960c33a593ca7c53.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"__variable_87c02c\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_87c02c\",\"children\":[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L9\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[]}]}]}]],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$La\"],\"globalErrorComponent\":\"$b\",\"missingSlots\":\"$Wc\"}]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Ranjani Narayanan | PhD Candidate @ Georgia Tech\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Expanding how agents can become teammates, not just tools.\"}],[\"$\",\"meta\",\"4\",{\"name\":\"next-size-adjust\"}]]\n5:null\n"])</script></body></html>